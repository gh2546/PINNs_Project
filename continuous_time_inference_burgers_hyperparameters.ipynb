{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "os.chdir(\"utils\")\n",
    "from burgers_utils import *\n",
    "from mlp_network import shared_model_func\n",
    "from plotting import list_tensor_to_list\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/burgers_shock.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from the burgers_shock.mat\n",
    "# usol in the paper's script has been reffered as Exact\n",
    "x, t, usol = load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a spatial-temporal grid\n",
    "X, T = mesh_grid(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test data set\n",
    "# X_test is reffered as X_star\n",
    "# y_test is reffered as u_star\n",
    "X_test, y_test = test_data(X, T, usol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain bounds \n",
    "lb, ub = domain_bounds(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of collocation points i.e. number of training points for f\n",
    "N_f = 10000\n",
    "# Number of initial and boudary conditions to train the model for u\n",
    "N_u = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In Physics-informed neural networks, we are predicting a latent variable u (x,t) and structure of \n",
    "### the pde f(u,x, t). variables with \"u_train\" in them corresponds to the training example required for u \n",
    "### and \"f_train\" corresponds to the training example required for f\n",
    "### We don't have \"y_f_train\" because it's value is always zero and we specified it in the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the the paper they are reffered as X_u_train, X_f_train and u_train\n",
    "x_f, x_u, y_u = training_data(X, T, usol, lb, ub, N_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the entire initial and boundary conditions we will select N_u number of x,t,u for the training\n",
    "idx = np.random.choice(x_u.shape[0], N_u, replace=False)\n",
    "X_u_train = x_u[idx, :]\n",
    "y_u_train = y_u[idx, :]\n",
    "# Stacking collocation points and IC and BC condtions\n",
    "# this will be used for imposing the structure of the Partial Differential Equation\n",
    "X_f_train = np.vstack([x_f, X_u_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the number of layers in the neural network shared between u and f\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "# Specifying the coefficient of viscosity\n",
    "nu = 0.01/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we are investigating different optimizers, learning rate, depth and widht of the network.\n",
    "## We are not changing the activation functions (just keeping the same as specified in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates used for hyparameters optimization are: [0.0009, 0.0397, 0.0098, 0.0248]\n",
      "\n",
      "Total trials for the hyperparameters search are: 144\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optim = ['Adam', 'RMSprop', 'SGD']\n",
    "lr_rate = []\n",
    "# Trying to perform random grid search by getting random learning rate\n",
    "std_rate = [1e-3, 5*1e-2, 1e-2, 1e-1]\n",
    "for i in range(4):\n",
    "    a = np.round(np.random.uniform(0, 1, size=1)*std_rate[i], 4)\n",
    "    lr_rate.append(a[0])\n",
    "print(\"Learning rates used for hyparameters optimization are: {}\\n\".format(lr_rate))\n",
    "depth = [4, 6, 8, 10] # Number of layers\n",
    "width = [10, 20, 30] # Number of neurons each layer\n",
    "print(\"Total trials for the hyperparameters search are: {}\\n\".format(len(optim) * len(lr_rate) * len(depth) * len(width)))\n",
    "print()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def model_build_compile(x_f, t_f, x_u, t_u,u, shared_model, loss_function, optimizer):\n",
    "    '''\n",
    "    model_build_compile: function will build the model, compile with loss function and optimizer,\n",
    "    calculate the gradients for weights and updating them automatically\n",
    "    Arguemnts:\n",
    "    x_f-- tensorflow batch dataset of shape (None, 1) [Pass x training data for collocation f]\n",
    "    t_f-- tensorflow batch dataset of shape (None, 1) [Pass t training data for collocation f]\n",
    "    x_u-- a numpy ndarray of shape (None, 1) [Pass x training data for latent variable u]\n",
    "    t_u-- a numpy ndarray of shape (None, 1) [Pass t training data for latent variable u]\n",
    "    u-- a numpy ndarray of shape (None, 1) [Pass training labels for latent variable u]\n",
    "    shared_model-- the keras model which is shared between u and f network\n",
    "    loss_function-- the keras loss function (for this project we use MSE)\n",
    "    optimizer-- the keras optimizer function (please specify the name, learning rate)\n",
    "\n",
    "    Returns\n",
    "    loss_u-- a mean squared tensorflow loss calcuated for variable u\n",
    "    loss_f-- a mean squared tensorflow loss calcuated for collocation f\n",
    "    loss_combine-- combinted loss of variable u and collocation f loss_combine = loss_u + loss_f\n",
    "    '''\n",
    "    # We have 2 different loss functions here\n",
    "    # loss_1 corresponds to loss in u\n",
    "    # loss_2 corresponds to loss in f\n",
    "    # Typicall plan, i.e. build model, compile model and fit model were not working in our case\n",
    "    # We referred this link for training the model\n",
    "    # Reference: https://www.tensorflow.org/guide/function\n",
    "    # Reference: https://keras.io/api/optimizers/#learning-rate-decay--scheduling\n",
    "    # Reference: https://colab.research.google.com/drive/1lo7Kf8zTb-DF_MjkO8Y07sYELnX3BNUR#scrollTo=GkimJNtepkKi\n",
    "    # Reference: https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/\n",
    "    # Reference: https://github.com/helonayala/pinn/blob/main/01_DeepVIV_sec21.ipynb\n",
    "    # This apprach i.e. optmizers.minimize(cost/loss) is also mentioned in the original paper\n",
    "\n",
    "    # In the paper, they specify mean squared error for variable u and f\n",
    "\n",
    "    # learning schedule for the optimizer\n",
    "\n",
    "    # In the original paper, they used scipy \"L-BFGS\" optimizer but we are using Adam\n",
    "    # L-BFGS is not available in tf. We can get it via tensorflow probability distribution but it's available\n",
    "    # for tf>=2.3\n",
    "#     if opt == 'Adam':\n",
    "#         optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "    # for the pde structure we need some derivatives of u, so we are using gradient tape to do it for us\n",
    "    # Reference: https://www.tensorflow.org/guide/autodiff\n",
    "    with tf.GradientTape() as tape_out:\n",
    "        # Trainign for variable u i.e IC and BC\n",
    "        u_pred = shared_model([x_u, t_u], training=True)\n",
    "        loss_u = loss_function(u, u_pred)\n",
    "\n",
    "        # Trainign for variable f i.e collocation points\n",
    "        with tf.GradientTape(persistent=True) as tape_in:\n",
    "            tape_in.watch(x_f)\n",
    "            tape_in.watch(t_f)\n",
    "\n",
    "            u_f = shared_model([x_f, t_f], training=True)\n",
    "            # Making a PDE net using automatic differentiation technique\n",
    "            # f = u_t + u * u_x - nu * u_xx\n",
    "            # Calling gradient tape here, because want to trace everything\n",
    "            # term1 ()\n",
    "            u_x = tape_in.gradient(u_f, x_f)\n",
    "            # term 2\n",
    "            u_t = tape_in.gradient(u_f, t_f)\n",
    "        #term 3\n",
    "        u_xx = tape_in.gradient(u_x, x_f)\n",
    "\n",
    "        f_pred = u_t + u_f * u_x - 0.01/np.pi*u_xx\n",
    "        # Value of f_pred is zero\n",
    "        loss_f = loss_function(f_pred, tf.convert_to_tensor(0, dtype=tf.float64))\n",
    "\n",
    "        # Once we calculate loss for each variable and now combine them\n",
    "        # MSE(u, u_pred) + MSE(0, f_pred)\n",
    "        loss_combine = loss_u + loss_f\n",
    "\n",
    "    # As given on the webpages\n",
    "    grads = tape_out.gradient(loss_combine, shared_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, shared_model.trainable_weights))\n",
    "\n",
    "    del loss_function\n",
    "    del optimizer\n",
    "    return loss_u, loss_f, loss_combine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_n_model(track_dict, best=20):\n",
    "    new_dict = {}\n",
    "    error_track = []\n",
    "    best_model = []\n",
    "    for k, v in track_dict.items():\n",
    "        for k1,v1 in v.items():\n",
    "            if k1 == 'error':\n",
    "                error_track.append(v1)\n",
    "                best_model.append(int(k))\n",
    "    error_track_1, best_model_1 = zip(*sorted(zip(error_track, best_model)))\n",
    "    for model in best_model_1[0:best]:\n",
    "#         print(\"************************\")\n",
    "#         print(\"Best models are: \\n\")\n",
    "#         print(track_dict['{}'.format(model)])\n",
    "#         print(\"************************\\n\")\n",
    "        new_dict['{}'.format(model)] = track_dict['{}'.format(model)]\n",
    "    return new_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For different learning rates\n",
    "def param_tuning(optim, lr_rate, depth, width, loss_function, train_dataset):\n",
    "    track_dict = {}\n",
    "    inp_num = 2\n",
    "    out_num = 1\n",
    "    klm = 0\n",
    "    for opt in tqdm(optim):\n",
    "        for lr in lr_rate:\n",
    "            # For different number of layers in a network\n",
    "            for dep in depth:\n",
    "                # For different number of units in a layer\n",
    "                for wid in width:\n",
    "                    small_dict = {}\n",
    "                    # Creating a list of size number of layers + 2\n",
    "                    layers = [None]*(dep+2)\n",
    "                    # Assigning size of input = 2\n",
    "                    layers[0] = inp_num\n",
    "                    # Assigning size of output = 1\n",
    "                    layers[-1] = out_num\n",
    "                    # Assigning number of neurons in hidden layers\n",
    "                    layers[1:-1] = wid*np.ones(dep, dtype=int)\n",
    "                    # Creating a model\n",
    "                    shared_model = shared_model_func(layers=layers, lb=lb, ub = ub, norm = True)\n",
    "                    # Keeping the same loss function as specified in the paper\n",
    "                    # Keeping the lear_rate)sched =. False\n",
    "                    optimizer = choose_optimizer(lr=lr, ds=100, er=0.96, opt=opt, lear_rate_sched=False)\n",
    "                    # Fixing maximum number of epochs \n",
    "                    max_Iter = 1000\n",
    "                    loss_model = []\n",
    "                    start = time.time()\n",
    "                    for epoch in range(max_Iter):\n",
    "                        for (X_f_train, t_f_train) in train_dataset:   \n",
    "                            # Passing the entire data in a single batch (That's how they did in the original paper)\n",
    "                            _, _, loss_combine = model_build_compile(x_f=X_f_train, t_f=t_f_train, \n",
    "                                                               x_u = X_u_train[:,0:1], t_u = X_u_train[:,1:2],\n",
    "                                                               u = y_u_train, shared_model=shared_model, \n",
    "                                                               loss_function=loss_function,\n",
    "                                                               optimizer=optimizer)\n",
    "\n",
    "                            loss_model.append(loss_combine)\n",
    "                    y_hat = predict(shared_model, X_test)\n",
    "                    small_dict['optimizer'] = opt\n",
    "                    small_dict['learning_rate'] = lr\n",
    "                    small_dict['number of layer'] = dep\n",
    "                    small_dict['number of neurons'] = wid\n",
    "                    small_dict['loss model'] = list_tensor_to_list(loss_model)\n",
    "                    small_dict['error'] = error_loss(y_test, y_hat)\n",
    "                    track_dict['{}'.format(klm)] = small_dict\n",
    "                    end = time.time()\n",
    "                    if klm%24 == 0:\n",
    "                        best_models = best_n_model(track_dict=track_dict, best=20)\n",
    "                        df = pd.DataFrame.from_dict(track_dict,orient='index')\n",
    "                        file = '../hyper_Burgers/dict_burgers'\n",
    "                        df.to_csv(file)\n",
    "                        \n",
    "                    print(\"*******************************************************************************\\n\")\n",
    "                    print(\"Trial {} has been completed\".format(klm))\n",
    "                    print(\"Time took to complete the trial is {}\".format(end-start))\n",
    "                    print(\"Total error in the solution is: {:e} \".format(error_loss(y_test, y_hat)))\n",
    "                    print(\"Network trained is: {}\".format(layers))\n",
    "                    klm +=1\n",
    "                    print(\"Details are: Optimizer: {0}, Learning Rate: {1}, Depth: {2}, Widht: {3}\".format(opt, lr, dep, wid))\n",
    "                    print(\"Deleting the current trained model\")\n",
    "                    del shared_model\n",
    "                    del optimizer\n",
    "                    del small_dict\n",
    "                    del loss_model\n",
    "#                     del loss_function\n",
    "#                     del optimizer\n",
    "                    print(\"\\n*******************************************************************************\\n\")\n",
    "    return track_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 0 has been completed\n",
      "Time took to complete the trial is 65.50399088859558\n",
      "Total error in the solution is: 5.384618e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 1 has been completed\n",
      "Time took to complete the trial is 66.1519467830658\n",
      "Total error in the solution is: 4.742121e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 2 has been completed\n",
      "Time took to complete the trial is 65.10178732872009\n",
      "Total error in the solution is: 4.889529e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 3 has been completed\n",
      "Time took to complete the trial is 75.56617140769958\n",
      "Total error in the solution is: 4.244109e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 4 has been completed\n",
      "Time took to complete the trial is 75.20286989212036\n",
      "Total error in the solution is: 4.600092e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 5 has been completed\n",
      "Time took to complete the trial is 74.73857641220093\n",
      "Total error in the solution is: 3.852212e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 6 has been completed\n",
      "Time took to complete the trial is 84.48275637626648\n",
      "Total error in the solution is: 3.211539e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 7 has been completed\n",
      "Time took to complete the trial is 84.66278314590454\n",
      "Total error in the solution is: 4.270990e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 8 has been completed\n",
      "Time took to complete the trial is 84.22713017463684\n",
      "Total error in the solution is: 4.301144e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 9 has been completed\n",
      "Time took to complete the trial is 95.65050268173218\n",
      "Total error in the solution is: 4.001991e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 10 has been completed\n",
      "Time took to complete the trial is 93.94189500808716\n",
      "Total error in the solution is: 3.166552e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 11 has been completed\n",
      "Time took to complete the trial is 93.91740894317627\n",
      "Total error in the solution is: 3.026928e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0009, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 12 has been completed\n",
      "Time took to complete the trial is 64.16230010986328\n",
      "Total error in the solution is: 2.207815e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 13 has been completed\n",
      "Time took to complete the trial is 63.59333157539368\n",
      "Total error in the solution is: 4.132416e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 14 has been completed\n",
      "Time took to complete the trial is 63.45529341697693\n",
      "Total error in the solution is: 4.469931e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 15 has been completed\n",
      "Time took to complete the trial is 74.32647061347961\n",
      "Total error in the solution is: 5.543004e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 16 has been completed\n",
      "Time took to complete the trial is 74.09260725975037\n",
      "Total error in the solution is: 1.000959e+00 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 17 has been completed\n",
      "Time took to complete the trial is 73.89776825904846\n",
      "Total error in the solution is: 4.456051e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 18 has been completed\n",
      "Time took to complete the trial is 84.36474013328552\n",
      "Total error in the solution is: 4.176916e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 19 has been completed\n",
      "Time took to complete the trial is 84.22831916809082\n",
      "Total error in the solution is: 9.104651e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 20 has been completed\n",
      "Time took to complete the trial is 84.17585444450378\n",
      "Total error in the solution is: 6.040830e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 21 has been completed\n",
      "Time took to complete the trial is 94.50833296775818\n",
      "Total error in the solution is: 5.768372e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 22 has been completed\n",
      "Time took to complete the trial is 97.75112628936768\n",
      "Total error in the solution is: 6.087420e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 23 has been completed\n",
      "Time took to complete the trial is 94.04324269294739\n",
      "Total error in the solution is: 5.719008e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0397, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 24 has been completed\n",
      "Time took to complete the trial is 63.85397934913635\n",
      "Total error in the solution is: 3.877572e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 25 has been completed\n",
      "Time took to complete the trial is 63.493486642837524\n",
      "Total error in the solution is: 3.778151e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 26 has been completed\n",
      "Time took to complete the trial is 63.3068904876709\n",
      "Total error in the solution is: 3.698174e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 27 has been completed\n",
      "Time took to complete the trial is 73.69081974029541\n",
      "Total error in the solution is: 1.768805e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 28 has been completed\n",
      "Time took to complete the trial is 73.5889253616333\n",
      "Total error in the solution is: 1.705509e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 29 has been completed\n",
      "Time took to complete the trial is 73.82439374923706\n",
      "Total error in the solution is: 3.039557e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 30 has been completed\n",
      "Time took to complete the trial is 83.76193118095398\n",
      "Total error in the solution is: 9.572514e-02 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 31 has been completed\n",
      "Time took to complete the trial is 84.56639456748962\n",
      "Total error in the solution is: 5.280483e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 32 has been completed\n",
      "Time took to complete the trial is 84.4305579662323\n",
      "Total error in the solution is: 4.180993e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 33 has been completed\n",
      "Time took to complete the trial is 94.12500596046448\n",
      "Total error in the solution is: 2.913727e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 34 has been completed\n",
      "Time took to complete the trial is 93.60671591758728\n",
      "Total error in the solution is: 4.227628e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 35 has been completed\n",
      "Time took to complete the trial is 93.72126960754395\n",
      "Total error in the solution is: 5.215272e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0098, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 36 has been completed\n",
      "Time took to complete the trial is 63.7361478805542\n",
      "Total error in the solution is: 4.569158e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 37 has been completed\n",
      "Time took to complete the trial is 63.73188805580139\n",
      "Total error in the solution is: 4.486128e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 38 has been completed\n",
      "Time took to complete the trial is 63.559741497039795\n",
      "Total error in the solution is: 5.282397e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 39 has been completed\n",
      "Time took to complete the trial is 73.4970977306366\n",
      "Total error in the solution is: 3.147462e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 40 has been completed\n",
      "Time took to complete the trial is 77.77979874610901\n",
      "Total error in the solution is: 6.401466e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 41 has been completed\n",
      "Time took to complete the trial is 73.89637899398804\n",
      "Total error in the solution is: 4.397940e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 42 has been completed\n",
      "Time took to complete the trial is 83.83413648605347\n",
      "Total error in the solution is: 4.051629e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 43 has been completed\n",
      "Time took to complete the trial is 83.5592589378357\n",
      "Total error in the solution is: 5.005694e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 44 has been completed\n",
      "Time took to complete the trial is 84.0071907043457\n",
      "Total error in the solution is: 6.616032e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 45 has been completed\n",
      "Time took to complete the trial is 93.72869038581848\n",
      "Total error in the solution is: 3.269870e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 46 has been completed\n",
      "Time took to complete the trial is 93.45114350318909\n",
      "Total error in the solution is: 8.805450e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [1:03:32<2:07:04, 3812.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 47 has been completed\n",
      "Time took to complete the trial is 93.83360409736633\n",
      "Total error in the solution is: 5.489054e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0248, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 48 has been completed\n",
      "Time took to complete the trial is 70.44501781463623\n",
      "Total error in the solution is: 5.247287e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 49 has been completed\n",
      "Time took to complete the trial is 70.28239560127258\n",
      "Total error in the solution is: 5.134240e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 50 has been completed\n",
      "Time took to complete the trial is 70.15137815475464\n",
      "Total error in the solution is: 5.198645e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 51 has been completed\n",
      "Time took to complete the trial is 87.28230166435242\n",
      "Total error in the solution is: 5.704983e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 52 has been completed\n",
      "Time took to complete the trial is 84.28539443016052\n",
      "Total error in the solution is: 4.818317e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 53 has been completed\n",
      "Time took to complete the trial is 83.33739352226257\n",
      "Total error in the solution is: 4.881076e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 54 has been completed\n",
      "Time took to complete the trial is 96.00208783149719\n",
      "Total error in the solution is: 5.311200e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 55 has been completed\n",
      "Time took to complete the trial is 96.16960978507996\n",
      "Total error in the solution is: 4.802382e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 56 has been completed\n",
      "Time took to complete the trial is 96.06734132766724\n",
      "Total error in the solution is: 4.835926e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 57 has been completed\n",
      "Time took to complete the trial is 109.02201747894287\n",
      "Total error in the solution is: 5.098436e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 58 has been completed\n",
      "Time took to complete the trial is 109.5644543170929\n",
      "Total error in the solution is: 4.434330e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 59 has been completed\n",
      "Time took to complete the trial is 109.16317319869995\n",
      "Total error in the solution is: 4.321112e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0009, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 60 has been completed\n",
      "Time took to complete the trial is 70.34704184532166\n",
      "Total error in the solution is: 4.646809e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 61 has been completed\n",
      "Time took to complete the trial is 70.21427798271179\n",
      "Total error in the solution is: 7.288991e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 62 has been completed\n",
      "Time took to complete the trial is 70.33458662033081\n",
      "Total error in the solution is: 1.438831e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 63 has been completed\n",
      "Time took to complete the trial is 83.34921741485596\n",
      "Total error in the solution is: 5.662953e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 64 has been completed\n",
      "Time took to complete the trial is 86.1817409992218\n",
      "Total error in the solution is: 1.231408e+00 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 65 has been completed\n",
      "Time took to complete the trial is 83.83833861351013\n",
      "Total error in the solution is: 1.355851e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 66 has been completed\n",
      "Time took to complete the trial is 96.67329120635986\n",
      "Total error in the solution is: 6.231016e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 67 has been completed\n",
      "Time took to complete the trial is 96.15823912620544\n",
      "Total error in the solution is: 1.214415e+00 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 68 has been completed\n",
      "Time took to complete the trial is 95.93857192993164\n",
      "Total error in the solution is: 1.307546e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 69 has been completed\n",
      "Time took to complete the trial is 109.10119867324829\n",
      "Total error in the solution is: 1.001189e+00 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 70 has been completed\n",
      "Time took to complete the trial is 108.94251990318298\n",
      "Total error in the solution is: 1.182319e+00 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 71 has been completed\n",
      "Time took to complete the trial is 109.13725638389587\n",
      "Total error in the solution is: 1.396903e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0397, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 72 has been completed\n",
      "Time took to complete the trial is 70.42105340957642\n",
      "Total error in the solution is: 4.947485e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 73 has been completed\n",
      "Time took to complete the trial is 70.19002103805542\n",
      "Total error in the solution is: 4.855458e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 74 has been completed\n",
      "Time took to complete the trial is 70.18169140815735\n",
      "Total error in the solution is: 4.507532e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 75 has been completed\n",
      "Time took to complete the trial is 83.33588027954102\n",
      "Total error in the solution is: 4.851445e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 76 has been completed\n",
      "Time took to complete the trial is 83.50703573226929\n",
      "Total error in the solution is: 4.268547e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 77 has been completed\n",
      "Time took to complete the trial is 82.98552918434143\n",
      "Total error in the solution is: 5.144360e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 78 has been completed\n",
      "Time took to complete the trial is 103.03143787384033\n",
      "Total error in the solution is: 3.929022e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 79 has been completed\n",
      "Time took to complete the trial is 98.28431272506714\n",
      "Total error in the solution is: 4.804495e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 80 has been completed\n",
      "Time took to complete the trial is 96.69223475456238\n",
      "Total error in the solution is: 6.641046e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 81 has been completed\n",
      "Time took to complete the trial is 109.32310080528259\n",
      "Total error in the solution is: 4.900516e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 82 has been completed\n",
      "Time took to complete the trial is 109.56988072395325\n",
      "Total error in the solution is: 4.599501e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 83 has been completed\n",
      "Time took to complete the trial is 109.06100559234619\n",
      "Total error in the solution is: 6.589172e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0098, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 84 has been completed\n",
      "Time took to complete the trial is 70.41829466819763\n",
      "Total error in the solution is: 5.261258e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 85 has been completed\n",
      "Time took to complete the trial is 70.4753930568695\n",
      "Total error in the solution is: 5.429270e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 86 has been completed\n",
      "Time took to complete the trial is 70.34480237960815\n",
      "Total error in the solution is: 1.099039e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 87 has been completed\n",
      "Time took to complete the trial is 83.23303580284119\n",
      "Total error in the solution is: 4.943427e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 88 has been completed\n",
      "Time took to complete the trial is 83.4547815322876\n",
      "Total error in the solution is: 9.044302e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 89 has been completed\n",
      "Time took to complete the trial is 83.02359366416931\n",
      "Total error in the solution is: 1.071268e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 90 has been completed\n",
      "Time took to complete the trial is 96.06455373764038\n",
      "Total error in the solution is: 4.805858e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 91 has been completed\n",
      "Time took to complete the trial is 96.62100863456726\n",
      "Total error in the solution is: 8.526432e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 92 has been completed\n",
      "Time took to complete the trial is 96.08899974822998\n",
      "Total error in the solution is: 1.356471e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 93 has been completed\n",
      "Time took to complete the trial is 109.09448266029358\n",
      "Total error in the solution is: 6.511261e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 94 has been completed\n",
      "Time took to complete the trial is 118.3671281337738\n",
      "Total error in the solution is: 1.001788e+00 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [2:15:55<1:06:11, 3971.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 95 has been completed\n",
      "Time took to complete the trial is 111.12175941467285\n",
      "Total error in the solution is: 1.242193e+00 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0248, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 96 has been completed\n",
      "Time took to complete the trial is 63.416512966156006\n",
      "Total error in the solution is: 8.756199e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 97 has been completed\n",
      "Time took to complete the trial is 63.192588090896606\n",
      "Total error in the solution is: 8.505250e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 98 has been completed\n",
      "Time took to complete the trial is 62.54315781593323\n",
      "Total error in the solution is: 8.625710e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 99 has been completed\n",
      "Time took to complete the trial is 72.76852083206177\n",
      "Total error in the solution is: 8.703036e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 100 has been completed\n",
      "Time took to complete the trial is 72.826740026474\n",
      "Total error in the solution is: 8.536784e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 101 has been completed\n",
      "Time took to complete the trial is 72.36103200912476\n",
      "Total error in the solution is: 8.524499e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 102 has been completed\n",
      "Time took to complete the trial is 82.56914734840393\n",
      "Total error in the solution is: 8.629121e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 103 has been completed\n",
      "Time took to complete the trial is 82.60780215263367\n",
      "Total error in the solution is: 8.725218e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 104 has been completed\n",
      "Time took to complete the trial is 82.65075469017029\n",
      "Total error in the solution is: 8.107216e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 105 has been completed\n",
      "Time took to complete the trial is 92.44443655014038\n",
      "Total error in the solution is: 8.729442e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 106 has been completed\n",
      "Time took to complete the trial is 92.50625801086426\n",
      "Total error in the solution is: 8.416969e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 107 has been completed\n",
      "Time took to complete the trial is 92.09726214408875\n",
      "Total error in the solution is: 7.678588e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0009, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 108 has been completed\n",
      "Time took to complete the trial is 62.673736810684204\n",
      "Total error in the solution is: 5.855777e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 109 has been completed\n",
      "Time took to complete the trial is 62.350205421447754\n",
      "Total error in the solution is: 5.902776e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 110 has been completed\n",
      "Time took to complete the trial is 63.275068283081055\n",
      "Total error in the solution is: 5.791947e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 111 has been completed\n",
      "Time took to complete the trial is 73.26592445373535\n",
      "Total error in the solution is: 5.988820e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 112 has been completed\n",
      "Time took to complete the trial is 73.2129909992218\n",
      "Total error in the solution is: 5.633696e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 113 has been completed\n",
      "Time took to complete the trial is 74.80540561676025\n",
      "Total error in the solution is: 5.536180e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 114 has been completed\n",
      "Time took to complete the trial is 83.31152939796448\n",
      "Total error in the solution is: 5.801422e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 115 has been completed\n",
      "Time took to complete the trial is 83.24454593658447\n",
      "Total error in the solution is: 5.503624e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 116 has been completed\n",
      "Time took to complete the trial is 82.88978385925293\n",
      "Total error in the solution is: 5.587172e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 117 has been completed\n",
      "Time took to complete the trial is 92.28032636642456\n",
      "Total error in the solution is: 5.559734e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 118 has been completed\n",
      "Time took to complete the trial is 92.44822669029236\n",
      "Total error in the solution is: 5.523358e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 119 has been completed\n",
      "Time took to complete the trial is 92.34537291526794\n",
      "Total error in the solution is: 7.170995e+37 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0397, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 120 has been completed\n",
      "Time took to complete the trial is 62.360515832901\n",
      "Total error in the solution is: 6.896715e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 121 has been completed\n",
      "Time took to complete the trial is 62.63285803794861\n",
      "Total error in the solution is: 6.138998e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 122 has been completed\n",
      "Time took to complete the trial is 62.504871129989624\n",
      "Total error in the solution is: 6.188466e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 123 has been completed\n",
      "Time took to complete the trial is 72.39270615577698\n",
      "Total error in the solution is: 6.786499e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 124 has been completed\n",
      "Time took to complete the trial is 72.55160212516785\n",
      "Total error in the solution is: 6.036211e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 125 has been completed\n",
      "Time took to complete the trial is 72.25412273406982\n",
      "Total error in the solution is: 6.021099e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 126 has been completed\n",
      "Time took to complete the trial is 82.55754780769348\n",
      "Total error in the solution is: 6.388541e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 127 has been completed\n",
      "Time took to complete the trial is 82.59009456634521\n",
      "Total error in the solution is: 5.974455e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 128 has been completed\n",
      "Time took to complete the trial is 82.757000207901\n",
      "Total error in the solution is: 5.933465e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 129 has been completed\n",
      "Time took to complete the trial is 92.27988719940186\n",
      "Total error in the solution is: 6.478506e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 130 has been completed\n",
      "Time took to complete the trial is 92.39394927024841\n",
      "Total error in the solution is: 5.721150e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 131 has been completed\n",
      "Time took to complete the trial is 92.52014923095703\n",
      "Total error in the solution is: 6.123310e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0098, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 132 has been completed\n",
      "Time took to complete the trial is 62.49234056472778\n",
      "Total error in the solution is: 5.956878e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 4, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 133 has been completed\n",
      "Time took to complete the trial is 66.40578889846802\n",
      "Total error in the solution is: 6.002579e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 4, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 134 has been completed\n",
      "Time took to complete the trial is 64.21845984458923\n",
      "Total error in the solution is: 5.984532e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 4, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 135 has been completed\n",
      "Time took to complete the trial is 73.26933741569519\n",
      "Total error in the solution is: 6.058223e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 6, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 136 has been completed\n",
      "Time took to complete the trial is 72.93772506713867\n",
      "Total error in the solution is: 5.736115e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 6, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 137 has been completed\n",
      "Time took to complete the trial is 72.53720211982727\n",
      "Total error in the solution is: 5.747746e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 6, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 138 has been completed\n",
      "Time took to complete the trial is 82.13887739181519\n",
      "Total error in the solution is: 5.944295e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 8, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 139 has been completed\n",
      "Time took to complete the trial is 82.41961932182312\n",
      "Total error in the solution is: 5.692893e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 8, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 140 has been completed\n",
      "Time took to complete the trial is 82.41960120201111\n",
      "Total error in the solution is: 5.522539e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 8, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 141 has been completed\n",
      "Time took to complete the trial is 92.41188716888428\n",
      "Total error in the solution is: 5.912809e-01 \n",
      "Network trained is: [2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 10, Widht: 10\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 142 has been completed\n",
      "Time took to complete the trial is 92.10740733146667\n",
      "Total error in the solution is: 5.525928e-01 \n",
      "Network trained is: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 10, Widht: 20\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [3:18:15<00:00, 3965.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 143 has been completed\n",
      "Time took to complete the trial is 92.31963396072388\n",
      "Total error in the solution is: 5.555078e-01 \n",
      "Network trained is: [2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0248, Depth: 10, Widht: 30\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_gen(X_f_train, batch_size=X_f_train.shape[0])\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "track_dict = param_tuning(optim, lr_rate, depth, width, loss_function, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.24173839343711734, 0.2...</td>\n",
       "      <td>0.095725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.669098973274231, 1.0847085118293762, 0.4912...</td>\n",
       "      <td>0.170551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.35738835483789444, 0.25885569863021374, 0.2...</td>\n",
       "      <td>0.176880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5199848860502243, 0.38453294336795807, 0.52...</td>\n",
       "      <td>0.220782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.26989802275784314, 0.22...</td>\n",
       "      <td>0.291373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.4858335256576538, 0.30999305471777916, 0.28...</td>\n",
       "      <td>0.302693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.6160300597548485, 3.6552160382270813, 0.780...</td>\n",
       "      <td>0.303956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.35738835483789444, 0.49027590453624725, 0.2...</td>\n",
       "      <td>0.314746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>[1.0859741270542145, 0.6248389929533005, 0.351...</td>\n",
       "      <td>0.316655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.21170908771455288, 0.2...</td>\n",
       "      <td>0.321154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.2871368032647297, 0.236...</td>\n",
       "      <td>0.326987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.8805493414402008, 1.7532535791397095, 0.453...</td>\n",
       "      <td>0.369817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.24911283422261477, 0.5979411005973816, 0.36...</td>\n",
       "      <td>0.377815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.6160300597548485, 0.4494305122643709, 0.373...</td>\n",
       "      <td>0.385221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5199848860502243, 0.3026476390659809, 0.221...</td>\n",
       "      <td>0.387757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.3358491421677172, 0.25...</td>\n",
       "      <td>0.392902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.38563643395900726, 0.36...</td>\n",
       "      <td>0.400199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.31384638062445447, 0.2...</td>\n",
       "      <td>0.405163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.24911283422261477, 7.499151587486267, 1.342...</td>\n",
       "      <td>0.413242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.3653780408203602, 0.22...</td>\n",
       "      <td>0.417692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "30      Adam         0.0098                8                 10   \n",
       "28      Adam         0.0098                6                 20   \n",
       "27      Adam         0.0098                6                 10   \n",
       "12      Adam         0.0397                4                 10   \n",
       "33      Adam         0.0098               10                 10   \n",
       "11      Adam         0.0009               10                 30   \n",
       "29      Adam         0.0098                6                 30   \n",
       "39      Adam         0.0248                6                 10   \n",
       "10      Adam         0.0009               10                 20   \n",
       "6       Adam         0.0009                8                 10   \n",
       "45      Adam         0.0248               10                 10   \n",
       "26      Adam         0.0098                4                 30   \n",
       "25      Adam         0.0098                4                 20   \n",
       "5       Adam         0.0009                6                 30   \n",
       "24      Adam         0.0098                4                 10   \n",
       "78   RMSprop         0.0098                8                 10   \n",
       "9       Adam         0.0009               10                 10   \n",
       "42      Adam         0.0248                8                 10   \n",
       "13      Adam         0.0397                4                 20   \n",
       "18      Adam         0.0397                8                 10   \n",
       "\n",
       "                                           loss model     error  \n",
       "30  [0.21567384619265795, 0.24173839343711734, 0.2...  0.095725  \n",
       "28  [0.669098973274231, 1.0847085118293762, 0.4912...  0.170551  \n",
       "27  [0.35738835483789444, 0.25885569863021374, 0.2...  0.176880  \n",
       "12  [0.5199848860502243, 0.38453294336795807, 0.52...  0.220782  \n",
       "33  [0.4157719947397709, 0.26989802275784314, 0.22...  0.291373  \n",
       "11  [0.4858335256576538, 0.30999305471777916, 0.28...  0.302693  \n",
       "29  [0.6160300597548485, 3.6552160382270813, 0.780...  0.303956  \n",
       "39  [0.35738835483789444, 0.49027590453624725, 0.2...  0.314746  \n",
       "10  [1.0859741270542145, 0.6248389929533005, 0.351...  0.316655  \n",
       "6   [0.21567384619265795, 0.21170908771455288, 0.2...  0.321154  \n",
       "45  [0.4157719947397709, 0.2871368032647297, 0.236...  0.326987  \n",
       "26  [0.8805493414402008, 1.7532535791397095, 0.453...  0.369817  \n",
       "25  [0.24911283422261477, 0.5979411005973816, 0.36...  0.377815  \n",
       "5   [0.6160300597548485, 0.4494305122643709, 0.373...  0.385221  \n",
       "24  [0.5199848860502243, 0.3026476390659809, 0.221...  0.387757  \n",
       "78  [0.21567384619265795, 0.3358491421677172, 0.25...  0.392902  \n",
       "9   [0.4157719947397709, 0.38563643395900726, 0.36...  0.400199  \n",
       "42  [0.21567384619265795, 0.31384638062445447, 0.2...  0.405163  \n",
       "13  [0.24911283422261477, 7.499151587486267, 1.342...  0.413242  \n",
       "18  [0.21567384619265795, 0.3653780408203602, 0.22...  0.417692  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = best_n_model(track_dict=track_dict, best=20)\n",
    "pd.DataFrame.from_dict(best_models,orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = pd.DataFrame.from_dict(best_models,orient='index')\n",
    "df_track = pd.DataFrame.from_dict(track_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../hyper_Burgers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../hyper_Burgers/'\n",
    "df_best.to_csv(file + 'best_dict')\n",
    "df_track.to_csv(file + 'track_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.24173839343711734, 0.2...</td>\n",
       "      <td>0.095725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.669098973274231, 1.0847085118293762, 0.4912...</td>\n",
       "      <td>0.170551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.35738835483789444, 0.25885569863021374, 0.2...</td>\n",
       "      <td>0.176880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5199848860502243, 0.38453294336795807, 0.52...</td>\n",
       "      <td>0.220782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.26989802275784314, 0.22...</td>\n",
       "      <td>0.291373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.4858335256576538, 0.30999305471777916, 0.28...</td>\n",
       "      <td>0.302693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.6160300597548485, 3.6552160382270813, 0.780...</td>\n",
       "      <td>0.303956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.35738835483789444, 0.49027590453624725, 0.2...</td>\n",
       "      <td>0.314746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>[1.0859741270542145, 0.6248389929533005, 0.351...</td>\n",
       "      <td>0.316655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.21170908771455288, 0.2...</td>\n",
       "      <td>0.321154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.2871368032647297, 0.236...</td>\n",
       "      <td>0.326987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.8805493414402008, 1.7532535791397095, 0.453...</td>\n",
       "      <td>0.369817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.24911283422261477, 0.5979411005973816, 0.36...</td>\n",
       "      <td>0.377815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.6160300597548485, 0.4494305122643709, 0.373...</td>\n",
       "      <td>0.385221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5199848860502243, 0.3026476390659809, 0.221...</td>\n",
       "      <td>0.387757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>78</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.3358491421677172, 0.25...</td>\n",
       "      <td>0.392902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.38563643395900726, 0.36...</td>\n",
       "      <td>0.400199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.31384638062445447, 0.2...</td>\n",
       "      <td>0.405163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.24911283422261477, 7.499151587486267, 1.342...</td>\n",
       "      <td>0.413242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.21567384619265795, 0.3653780408203602, 0.22...</td>\n",
       "      <td>0.417692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "0           30      Adam         0.0098                8                 10   \n",
       "1           28      Adam         0.0098                6                 20   \n",
       "2           27      Adam         0.0098                6                 10   \n",
       "3           12      Adam         0.0397                4                 10   \n",
       "4           33      Adam         0.0098               10                 10   \n",
       "5           11      Adam         0.0009               10                 30   \n",
       "6           29      Adam         0.0098                6                 30   \n",
       "7           39      Adam         0.0248                6                 10   \n",
       "8           10      Adam         0.0009               10                 20   \n",
       "9            6      Adam         0.0009                8                 10   \n",
       "10          45      Adam         0.0248               10                 10   \n",
       "11          26      Adam         0.0098                4                 30   \n",
       "12          25      Adam         0.0098                4                 20   \n",
       "13           5      Adam         0.0009                6                 30   \n",
       "14          24      Adam         0.0098                4                 10   \n",
       "15          78   RMSprop         0.0098                8                 10   \n",
       "16           9      Adam         0.0009               10                 10   \n",
       "17          42      Adam         0.0248                8                 10   \n",
       "18          13      Adam         0.0397                4                 20   \n",
       "19          18      Adam         0.0397                8                 10   \n",
       "\n",
       "                                           loss model     error  \n",
       "0   [0.21567384619265795, 0.24173839343711734, 0.2...  0.095725  \n",
       "1   [0.669098973274231, 1.0847085118293762, 0.4912...  0.170551  \n",
       "2   [0.35738835483789444, 0.25885569863021374, 0.2...  0.176880  \n",
       "3   [0.5199848860502243, 0.38453294336795807, 0.52...  0.220782  \n",
       "4   [0.4157719947397709, 0.26989802275784314, 0.22...  0.291373  \n",
       "5   [0.4858335256576538, 0.30999305471777916, 0.28...  0.302693  \n",
       "6   [0.6160300597548485, 3.6552160382270813, 0.780...  0.303956  \n",
       "7   [0.35738835483789444, 0.49027590453624725, 0.2...  0.314746  \n",
       "8   [1.0859741270542145, 0.6248389929533005, 0.351...  0.316655  \n",
       "9   [0.21567384619265795, 0.21170908771455288, 0.2...  0.321154  \n",
       "10  [0.4157719947397709, 0.2871368032647297, 0.236...  0.326987  \n",
       "11  [0.8805493414402008, 1.7532535791397095, 0.453...  0.369817  \n",
       "12  [0.24911283422261477, 0.5979411005973816, 0.36...  0.377815  \n",
       "13  [0.6160300597548485, 0.4494305122643709, 0.373...  0.385221  \n",
       "14  [0.5199848860502243, 0.3026476390659809, 0.221...  0.387757  \n",
       "15  [0.21567384619265795, 0.3358491421677172, 0.25...  0.392902  \n",
       "16  [0.4157719947397709, 0.38563643395900726, 0.36...  0.400199  \n",
       "17  [0.21567384619265795, 0.31384638062445447, 0.2...  0.405163  \n",
       "18  [0.24911283422261477, 7.499151587486267, 1.342...  0.413242  \n",
       "19  [0.21567384619265795, 0.3653780408203602, 0.22...  0.417692  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file+ 'best_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5199848860502243, 0.49136319756507874, 0.46...</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.24911283422261477, 0.22555065201595426, 0.2...</td>\n",
       "      <td>0.474212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.8805493414402008, 0.6395775079727173, 0.476...</td>\n",
       "      <td>0.488953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.35738835483789444, 0.33319417387247086, 0.3...</td>\n",
       "      <td>0.424411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.669098973274231, 0.46902719140052795, 0.329...</td>\n",
       "      <td>0.460009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.7193073034286499, 1.0514986217021942, 0.674...</td>\n",
       "      <td>0.569289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.7023464441299438, 1.6923798620700836, 2.321...</td>\n",
       "      <td>0.552254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.4157719947397709, 0.35198673978447914, 0.31...</td>\n",
       "      <td>0.591281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>[1.0859741270542145, 2.017742335796356, 0.3668...</td>\n",
       "      <td>0.552593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.4858335256576538, 2.890544295310974, 0.6056...</td>\n",
       "      <td>0.555508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "0             0      Adam         0.0009                4                 10   \n",
       "1             1      Adam         0.0009                4                 20   \n",
       "2             2      Adam         0.0009                4                 30   \n",
       "3             3      Adam         0.0009                6                 10   \n",
       "4             4      Adam         0.0009                6                 20   \n",
       "..          ...       ...            ...              ...                ...   \n",
       "139         139       SGD         0.0248                8                 20   \n",
       "140         140       SGD         0.0248                8                 30   \n",
       "141         141       SGD         0.0248               10                 10   \n",
       "142         142       SGD         0.0248               10                 20   \n",
       "143         143       SGD         0.0248               10                 30   \n",
       "\n",
       "                                            loss model     error  \n",
       "0    [0.5199848860502243, 0.49136319756507874, 0.46...  0.538462  \n",
       "1    [0.24911283422261477, 0.22555065201595426, 0.2...  0.474212  \n",
       "2    [0.8805493414402008, 0.6395775079727173, 0.476...  0.488953  \n",
       "3    [0.35738835483789444, 0.33319417387247086, 0.3...  0.424411  \n",
       "4    [0.669098973274231, 0.46902719140052795, 0.329...  0.460009  \n",
       "..                                                 ...       ...  \n",
       "139  [0.7193073034286499, 1.0514986217021942, 0.674...  0.569289  \n",
       "140  [0.7023464441299438, 1.6923798620700836, 2.321...  0.552254  \n",
       "141  [0.4157719947397709, 0.35198673978447914, 0.31...  0.591281  \n",
       "142  [1.0859741270542145, 2.017742335796356, 0.3668...  0.552593  \n",
       "143  [0.4858335256576538, 2.890544295310974, 0.6056...  0.555508  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file+ 'track_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
