{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir('utils')\n",
    "from schroding_utils import *\n",
    "from mlp_network import shared_model_func\n",
    "from plotting import list_tensor_to_list, plot_loss, three_plots_schrod, heat_map_schrod\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../hyperparams_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../hyper_Schrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/NLS.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data\n",
    "x, t, usol, usol_real, usol_img, usol_mag = load_data(file_path)\n",
    "\n",
    "## Creating spatio-temporal grid\n",
    "X, T = mesh_grid(x, t)\n",
    "\n",
    "## Domain bounds\n",
    "lb, ub = domain_bounds(-5.0, 5.0, 0.0, np.pi/2)\n",
    "\n",
    "## Number of initial conditions training points\n",
    "N0 = 50\n",
    "\n",
    "## Number of boundary condition training points\n",
    "N_b = 50\n",
    "\n",
    "## Number of PDE structure (i.e. collocation) training points\n",
    "N_f = 20000\n",
    "\n",
    "## size of the neural network\n",
    "## layers[0] == Input size\n",
    "## layers[-1] == Output size\n",
    "## layers[1:-1] == Number of units in between layers\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "\n",
    "## Preparing test data\n",
    "X_test, y_u_test, y_v_test, y_h_test = test_data(X, T, usol_real, usol_img, usol_mag)\n",
    "\n",
    "## Preparing training data\n",
    "## choosing N0 random initial conditions\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "X_x_IC_train = x[idx_x,:] # spatial grid for train\n",
    "X_u_IC_train = usol_real[idx_x,0:1] # real component for training\n",
    "X_v_IC_train = usol_img[idx_x,0:1] # imaginary component for training\n",
    "\n",
    "## chossing N_b boundary conditions\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "X_tb_train = t[idx_t,:]\n",
    "\n",
    "## Generating a latin-hypercube design\n",
    "X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "\n",
    "# Concating training arrays\n",
    "X_IC_train = np.concatenate((X_x_IC_train, 0*X_x_IC_train), 1) \n",
    "X_lb_train = np.concatenate((0*X_tb_train + lb[0], X_tb_train), 1)\n",
    "X_ub_train = np.concatenate((0*X_tb_train + ub[0], X_tb_train), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we are investigating different optimizers, learning rate, depth and widht of the network.\n",
    "## We are not changing the activation functions (just keeping the same as specified in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates used for hyparameters optimization are: [0.0004, 0.0038, 0.0769]\n",
      "\n",
      "Total trials for the hyperparameters search are: 81\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optim = ['Adam', 'RMSprop', 'SGD']\n",
    "lr_rate = []\n",
    "# Trying to perform random grid search by getting random learning rate\n",
    "std_rate = [1e-3, 1e-2, 1e-1]\n",
    "for i in range(3):\n",
    "    a = np.round(np.random.uniform(0, 1, size=1)*std_rate[i], 4)\n",
    "    lr_rate.append(a[0])\n",
    "print(\"Learning rates used for hyparameters optimization are: {}\\n\".format(lr_rate))\n",
    "depth = [2, 4, 6] # Number of layers\n",
    "width = [100, 200, 300] # Number of neurons each layer\n",
    "print(\"Total trials for the hyperparameters search are: {}\\n\".format(len(optim) * len(lr_rate) * len(depth) * len(width)))\n",
    "print()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_compile(x0, t0, x_lb, t_lb, x_ub, t_ub, x_f, t_f,shared_model, loss_function, optimizer, u0, v0):\n",
    "    '''\n",
    "    '''\n",
    "    # Typicall plan, i.e. build model, compile model and fit model were not working in our case\n",
    "    # We referred this link for training the model\n",
    "    # Reference: https://www.tensorflow.org/guide/function\n",
    "    # Reference: https://keras.io/api/optimizers/#learning-rate-decay--scheduling\n",
    "    # Reference: https://colab.research.google.com/drive/1lo7Kf8zTb-DF_MjkO8Y07sYELnX3BNUR#scrollTo=GkimJNtepkKi\n",
    "    # Reference: https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/\n",
    "    # Reference: https://github.com/helonayala/pinn/blob/main/01_DeepVIV_sec21.ipynb\n",
    "    # This apprach i.e. optmizers.minimize(cost/loss) is also mentioned in the original paper\n",
    "    # Reference: https://www.tensorflow.org/guide/autodiff\n",
    "    with tf.GradientTape() as tape_out:\n",
    "        uv = shared_model([x0, t0], training=True)\n",
    "        u0_pred = uv[:,0:1]\n",
    "        v0_pred = uv[:,1:2]\n",
    "\n",
    "        ## Loss function for initial conditon\n",
    "        loss_1 = loss_function(u0_pred, u0) # Real part\n",
    "        loss_2 = loss_function(v0_pred, v0) # Imaginary part\n",
    "        \n",
    "        x_lb = tf.convert_to_tensor(x_lb, dtype=tf.float64)\n",
    "        x_ub = tf.convert_to_tensor(x_ub, dtype=tf.float64)\n",
    "        x_f = tf.convert_to_tensor(x_f, dtype=tf.float64)\n",
    "        t_f = tf.convert_to_tensor(t_f, dtype=tf.float64)\n",
    "        with tf.GradientTape(persistent=True) as tape_1:\n",
    "            tape_1.watch(x_lb)\n",
    "            uv_lb = shared_model([x_lb, t_lb], training=True)\n",
    "            u_lb_pred = uv_lb[:,0:1]\n",
    "            v_lb_pred = uv_lb[:,1:2]\n",
    "            u_x_lb_pred = tape_1.gradient(u_lb_pred, x_lb)\n",
    "            v_x_lb_pred = tape_1.gradient(v_lb_pred, x_lb)\n",
    "\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape_2:\n",
    "            tape_2.watch(x_ub)\n",
    "            uv_ub = shared_model([x_ub, t_ub], training=True)\n",
    "            u_ub_pred = uv_ub[:,0:1]\n",
    "            v_ub_pred = uv_ub[:,1:2]\n",
    "            u_x_ub_pred = tape_2.gradient(u_ub_pred, x_ub)\n",
    "            v_x_ub_pred = tape_2.gradient(v_ub_pred, x_ub)\n",
    "\n",
    "        ## Loss functions for the boundary conditions\n",
    "        loss_3 = loss_function(u_lb_pred, u_ub_pred)\n",
    "        loss_4 = loss_function(v_lb_pred, v_ub_pred)\n",
    "        loss_5 = loss_function(u_x_lb_pred, u_x_ub_pred)\n",
    "        loss_6 = loss_function(v_x_lb_pred, v_x_ub_pred)\n",
    "\n",
    "\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape_3:\n",
    "            tape_3.watch(x_f)\n",
    "            tape_3.watch(t_f)\n",
    "            uv_f = shared_model([x_f, t_f], training=True)\n",
    "            u_f = uv_f[:,0:1]\n",
    "            v_f = uv_f[:,1:2]\n",
    "            u_x_f = tape_3.gradient(u_f, x_f)\n",
    "            v_x_f = tape_3.gradient(v_f, x_f)\n",
    "            u_t_f = tape_3.gradient(u_f, t_f)\n",
    "            v_t_f = tape_3.gradient(v_f, t_f)\n",
    "        u_xx_f = tape_3.gradient(u_x_f, x_f)\n",
    "        v_xx_f = tape_3.gradient(v_x_f, x_f)\n",
    "\n",
    "        f_u_pred = u_t_f + 0.5 * v_xx_f + (u_f**2 + v_f**2)*v_f\n",
    "        f_v_pred = v_t_f - 0.5 * u_xx_f - (u_f**2 + v_f**2)*u_f\n",
    "\n",
    "        ## Loss function for the collocation points\n",
    "        loss_7 = loss_function(f_u_pred, tf.convert_to_tensor(0, dtype=tf.float64))\n",
    "        loss_8 = loss_function(f_v_pred, tf.convert_to_tensor(0, dtype=tf.float64))\n",
    "\n",
    "        loss_combine = loss_1 + loss_2 + loss_3 + loss_4 + loss_5 + loss_6 + loss_7 + loss_8\n",
    "    grads = tape_out.gradient(loss_combine, shared_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, shared_model.trainable_weights))\n",
    "\n",
    "    return loss_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_n_model(track_dict, best=20):\n",
    "    new_dict = {}\n",
    "    error_track = []\n",
    "    best_model = []\n",
    "    for k, v in track_dict.items():\n",
    "        for k1,v1 in v.items():\n",
    "            if k1 == 'error':\n",
    "                error_track.append(v1)\n",
    "                best_model.append(int(k))\n",
    "    error_track_1, best_model_1 = zip(*sorted(zip(error_track, best_model)))\n",
    "    for model in best_model_1[0:best]:\n",
    "#         print(\"************************\")\n",
    "#         print(\"Best models are: \\n\")\n",
    "#         print(track_dict['{}'.format(model)])\n",
    "#         print(\"************************\\n\")\n",
    "        new_dict['{}'.format(model)] = track_dict['{}'.format(model)]\n",
    "    return new_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For different learning rates\n",
    "def param_tuning(optim, lr_rate, depth, width, loss_function, train_dataset):\n",
    "    track_dict = {}\n",
    "    inp_num = 2\n",
    "    out_num = 2\n",
    "    klm = 0\n",
    "    for opt in tqdm(optim):\n",
    "        for lr in lr_rate:\n",
    "            # For different number of layers in a network\n",
    "            for dep in depth:\n",
    "                # For different number of units in a layer\n",
    "                for wid in width:\n",
    "                    small_dict = {}\n",
    "                    # Creating a list of size number of layers + 2\n",
    "                    layers = [None]*(dep+2)\n",
    "                    # Assigning size of input = 2\n",
    "                    layers[0] = inp_num\n",
    "                    # Assigning size of output = 1\n",
    "                    layers[-1] = out_num\n",
    "                    # Assigning number of neurons in hidden layers\n",
    "                    layers[1:-1] = wid*np.ones(dep, dtype=int)\n",
    "                    # Creating a model\n",
    "                    shared_model = shared_model_func(layers, lb=None, ub=None, norm=False)\n",
    "                    # Keeping the same loss function as specified in the paper\n",
    "                    # Keeping the lear_rate)sched =. False\n",
    "                    optimizer = choose_optimizer(lr=lr, ds=100, er=0.96, opt=opt, lear_rate_sched=False)\n",
    "                    # Fixing maximum number of epochs \n",
    "                    max_Iter = 200\n",
    "                    loss_model = []\n",
    "                    start = time.time()\n",
    "                    for epoch in range(max_Iter):\n",
    "                        for (X_f_train1, t_f_train1) in train_dataset:   \n",
    "                            # Passing the entire data in a single batch (That's how they did in the original paper)\n",
    "                            loss_combine = model_build_compile(X_IC_train[:,0:1],\n",
    "                                                                        X_IC_train[:,1:2], X_lb_train[:,0:1], \n",
    "                                                                        X_lb_train[:,1:2], X_ub_train[:,0:1], \n",
    "                                                                         X_ub_train[:,1:2], X_f_train[:,0:1], \n",
    "                                                                        X_f_train[:,1:2], shared_model, loss_function,\n",
    "                                                                                    optimizer,X_u_IC_train, X_v_IC_train)\n",
    "\n",
    "                            loss_model.append(loss_combine)\n",
    "                    y_hat = predict(shared_model, X_test)\n",
    "                    u_hat, v_hat = y_hat[:,0:1], y_hat[:,1:2]\n",
    "                    h_hat = np.sqrt(u_hat**2 + v_hat**2)\n",
    "                    \n",
    "                    small_dict['optimizer'] = opt\n",
    "                    small_dict['learning_rate'] = lr\n",
    "                    small_dict['number of layer'] = dep\n",
    "                    small_dict['number of neurons'] = wid\n",
    "                    small_dict['loss model'] = list_tensor_to_list(loss_model)\n",
    "                    small_dict['error'] = error_loss(y_h_test, h_hat)\n",
    "                    track_dict['{}'.format(klm)] = small_dict\n",
    "                    end = time.time()\n",
    "                    if klm%9 == 0:\n",
    "                        best_models = best_n_model(track_dict=track_dict, best=20)\n",
    "                        df = pd.DataFrame.from_dict(track_dict,orient='index')\n",
    "                        file = '../hyperparams_analysis/hyper_Schrod/dict_schrod'\n",
    "                        df.to_csv(file)\n",
    "                        \n",
    "                    print(\"*******************************************************************************\\n\")\n",
    "                    print(\"Trial {} has been completed\".format(klm))\n",
    "                    print(\"Time took to complete the trial is {}\".format(end-start))\n",
    "                    print(\"Total error in the solution is: {:e} \".format(error_loss(y_h_test, h_hat)))\n",
    "                    print(\"Network trained is: {}\".format(layers))\n",
    "                    klm +=1\n",
    "                    print(\"Details are: Optimizer: {0}, Learning Rate: {1}, Depth: {2}, Widht: {3}\".format(opt, lr, dep, wid))\n",
    "                    print(\"Deleting the current trained model\")\n",
    "                    del shared_model\n",
    "                    del optimizer\n",
    "                    del small_dict\n",
    "                    del loss_model\n",
    "#                     del loss_function\n",
    "#                     del optimizer\n",
    "                    print(\"\\n*******************************************************************************\\n\")\n",
    "    return track_dict\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 0 has been completed\n",
      "Time took to complete the trial is 27.14647388458252\n",
      "Total error in the solution is: 7.082919e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 1 has been completed\n",
      "Time took to complete the trial is 49.865201473236084\n",
      "Total error in the solution is: 6.887486e-01 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 2 has been completed\n",
      "Time took to complete the trial is 75.93690299987793\n",
      "Total error in the solution is: 7.255001e-01 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 3 has been completed\n",
      "Time took to complete the trial is 52.673743724823\n",
      "Total error in the solution is: 4.491381e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 4 has been completed\n",
      "Time took to complete the trial is 113.11703205108643\n",
      "Total error in the solution is: 5.224766e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 5 has been completed\n",
      "Time took to complete the trial is 183.86961913108826\n",
      "Total error in the solution is: 5.225764e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 6 has been completed\n",
      "Time took to complete the trial is 78.7388026714325\n",
      "Total error in the solution is: 4.262778e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 7 has been completed\n",
      "Time took to complete the trial is 176.90217566490173\n",
      "Total error in the solution is: 4.485857e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 8 has been completed\n",
      "Time took to complete the trial is 292.6596076488495\n",
      "Total error in the solution is: 6.904067e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0004, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 9 has been completed\n",
      "Time took to complete the trial is 26.34446692466736\n",
      "Total error in the solution is: 5.141688e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 10 has been completed\n",
      "Time took to complete the trial is 49.220516204833984\n",
      "Total error in the solution is: 6.959924e-01 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 11 has been completed\n",
      "Time took to complete the trial is 75.33179330825806\n",
      "Total error in the solution is: 9.511431e-01 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 12 has been completed\n",
      "Time took to complete the trial is 52.299259424209595\n",
      "Total error in the solution is: 4.894907e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 13 has been completed\n",
      "Time took to complete the trial is 112.95425605773926\n",
      "Total error in the solution is: 5.938431e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 14 has been completed\n",
      "Time took to complete the trial is 183.9891767501831\n",
      "Total error in the solution is: 7.957079e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 15 has been completed\n",
      "Time took to complete the trial is 79.55790042877197\n",
      "Total error in the solution is: 4.533042e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 16 has been completed\n",
      "Time took to complete the trial is 176.40818977355957\n",
      "Total error in the solution is: 7.113387e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 17 has been completed\n",
      "Time took to complete the trial is 290.3434648513794\n",
      "Total error in the solution is: 7.499837e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0038, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 18 has been completed\n",
      "Time took to complete the trial is 26.989768028259277\n",
      "Total error in the solution is: 7.966841e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 19 has been completed\n",
      "Time took to complete the trial is 49.38967514038086\n",
      "Total error in the solution is: 1.343223e+00 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 20 has been completed\n",
      "Time took to complete the trial is 74.93442010879517\n",
      "Total error in the solution is: 2.231114e+00 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 21 has been completed\n",
      "Time took to complete the trial is 52.784244537353516\n",
      "Total error in the solution is: 9.053393e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 22 has been completed\n",
      "Time took to complete the trial is 111.27115941047668\n",
      "Total error in the solution is: 1.256362e+00 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 23 has been completed\n",
      "Time took to complete the trial is 177.79651713371277\n",
      "Total error in the solution is: 1.858601e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 24 has been completed\n",
      "Time took to complete the trial is 78.86599659919739\n",
      "Total error in the solution is: 7.978644e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 25 has been completed\n",
      "Time took to complete the trial is 173.60770845413208\n",
      "Total error in the solution is: 1.805324e+00 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [52:07<1:44:14, 3127.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 26 has been completed\n",
      "Time took to complete the trial is 281.9604752063751\n",
      "Total error in the solution is: 4.904361e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: Adam, Learning Rate: 0.0769, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 27 has been completed\n",
      "Time took to complete the trial is 27.19817304611206\n",
      "Total error in the solution is: 6.681151e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 28 has been completed\n",
      "Time took to complete the trial is 49.83863925933838\n",
      "Total error in the solution is: 6.873926e-01 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 29 has been completed\n",
      "Time took to complete the trial is 75.8061671257019\n",
      "Total error in the solution is: 7.624108e-01 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 30 has been completed\n",
      "Time took to complete the trial is 53.09074282646179\n",
      "Total error in the solution is: 5.006457e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 31 has been completed\n",
      "Time took to complete the trial is 113.77487325668335\n",
      "Total error in the solution is: 6.652517e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 32 has been completed\n",
      "Time took to complete the trial is 184.33531260490417\n",
      "Total error in the solution is: 7.427503e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 33 has been completed\n",
      "Time took to complete the trial is 79.29926347732544\n",
      "Total error in the solution is: 5.332816e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 34 has been completed\n",
      "Time took to complete the trial is 177.67227864265442\n",
      "Total error in the solution is: 7.363256e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 35 has been completed\n",
      "Time took to complete the trial is 293.8417844772339\n",
      "Total error in the solution is: 7.898151e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0004, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 36 has been completed\n",
      "Time took to complete the trial is 26.751120805740356\n",
      "Total error in the solution is: 6.558462e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 37 has been completed\n",
      "Time took to complete the trial is 49.73639392852783\n",
      "Total error in the solution is: 7.800724e-01 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 38 has been completed\n",
      "Time took to complete the trial is 75.599933385849\n",
      "Total error in the solution is: 1.758985e+00 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 39 has been completed\n",
      "Time took to complete the trial is 52.9443085193634\n",
      "Total error in the solution is: 7.215836e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 40 has been completed\n",
      "Time took to complete the trial is 113.79968857765198\n",
      "Total error in the solution is: 8.734898e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 41 has been completed\n",
      "Time took to complete the trial is 183.43503761291504\n",
      "Total error in the solution is: 1.959085e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 42 has been completed\n",
      "Time took to complete the trial is 79.31899571418762\n",
      "Total error in the solution is: 6.893391e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 43 has been completed\n",
      "Time took to complete the trial is 182.81745028495789\n",
      "Total error in the solution is: 9.364858e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 44 has been completed\n",
      "Time took to complete the trial is 292.0090444087982\n",
      "Total error in the solution is: 1.134163e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0038, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 45 has been completed\n",
      "Time took to complete the trial is 27.312673807144165\n",
      "Total error in the solution is: 8.925432e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 46 has been completed\n",
      "Time took to complete the trial is 49.791892528533936\n",
      "Total error in the solution is: 3.172204e+00 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 47 has been completed\n",
      "Time took to complete the trial is 75.44838500022888\n",
      "Total error in the solution is: 1.960026e+00 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 48 has been completed\n",
      "Time took to complete the trial is 52.95378375053406\n",
      "Total error in the solution is: 8.736284e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 49 has been completed\n",
      "Time took to complete the trial is 111.73655533790588\n",
      "Total error in the solution is: 4.570093e+00 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 50 has been completed\n",
      "Time took to complete the trial is 180.34572005271912\n",
      "Total error in the solution is: 2.290245e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 51 has been completed\n",
      "Time took to complete the trial is 78.65396785736084\n",
      "Total error in the solution is: 2.511969e+00 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 52 has been completed\n",
      "Time took to complete the trial is 173.5528244972229\n",
      "Total error in the solution is: 6.933819e+00 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [1:44:32<52:12, 3132.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 53 has been completed\n",
      "Time took to complete the trial is 283.0096571445465\n",
      "Total error in the solution is: 2.769627e+00 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: RMSprop, Learning Rate: 0.0769, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 54 has been completed\n",
      "Time took to complete the trial is 27.170701026916504\n",
      "Total error in the solution is: 8.130094e-01 \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 55 has been completed\n",
      "Time took to complete the trial is 50.07662773132324\n",
      "Total error in the solution is: 7.910996e-01 \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 56 has been completed\n",
      "Time took to complete the trial is 76.00796151161194\n",
      "Total error in the solution is: 8.092554e-01 \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 57 has been completed\n",
      "Time took to complete the trial is 53.29099893569946\n",
      "Total error in the solution is: 7.580525e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 58 has been completed\n",
      "Time took to complete the trial is 113.68747186660767\n",
      "Total error in the solution is: 7.593383e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 59 has been completed\n",
      "Time took to complete the trial is 184.3041799068451\n",
      "Total error in the solution is: 7.598638e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 60 has been completed\n",
      "Time took to complete the trial is 79.47277569770813\n",
      "Total error in the solution is: 7.581880e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 61 has been completed\n",
      "Time took to complete the trial is 177.51708555221558\n",
      "Total error in the solution is: 7.266500e-01 \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 62 has been completed\n",
      "Time took to complete the trial is 293.34774899482727\n",
      "Total error in the solution is: 7.425685e-01 \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0004, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 63 has been completed\n",
      "Time took to complete the trial is 26.769654512405396\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 64 has been completed\n",
      "Time took to complete the trial is 49.21045255661011\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 65 has been completed\n",
      "Time took to complete the trial is 73.07381701469421\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 66 has been completed\n",
      "Time took to complete the trial is 52.27855944633484\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 67 has been completed\n",
      "Time took to complete the trial is 110.18609619140625\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 68 has been completed\n",
      "Time took to complete the trial is 173.08006286621094\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 69 has been completed\n",
      "Time took to complete the trial is 79.20858860015869\n",
      "Total error in the solution is: 6.603918e-01 \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 70 has been completed\n",
      "Time took to complete the trial is 171.02885794639587\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 71 has been completed\n",
      "Time took to complete the trial is 273.2032470703125\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0038, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 72 has been completed\n",
      "Time took to complete the trial is 26.500974655151367\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 2, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 73 has been completed\n",
      "Time took to complete the trial is 48.954500675201416\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 2, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 74 has been completed\n",
      "Time took to complete the trial is 72.83543229103088\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 2, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 75 has been completed\n",
      "Time took to complete the trial is 51.62398338317871\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 4, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 76 has been completed\n",
      "Time took to complete the trial is 109.8874123096466\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 4, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 77 has been completed\n",
      "Time took to complete the trial is 172.80152010917664\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 4, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 78 has been completed\n",
      "Time took to complete the trial is 76.43676137924194\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 100, 100, 100, 100, 100, 100, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 6, Widht: 100\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "*******************************************************************************\n",
      "\n",
      "Trial 79 has been completed\n",
      "Time took to complete the trial is 170.3949601650238\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 200, 200, 200, 200, 200, 200, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 6, Widht: 200\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [2:35:39<00:00, 3113.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "\n",
      "Trial 80 has been completed\n",
      "Time took to complete the trial is 272.73276257514954\n",
      "Total error in the solution is: nan \n",
      "Network trained is: [2, 300, 300, 300, 300, 300, 300, 2]\n",
      "Details are: Optimizer: SGD, Learning Rate: 0.0769, Depth: 6, Widht: 300\n",
      "Deleting the current trained model\n",
      "\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_gen(X_f_train, batch_size=X_f_train.shape[0])\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "track_dict = param_tuning(optim, lr_rate, depth, width, loss_function, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 0.8455816553614568, 1.007...</td>\n",
       "      <td>0.426278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>[2.5006211749550857, 3.2143473901419384, 2.130...</td>\n",
       "      <td>0.448586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 0.792291968610229, 0.8935...</td>\n",
       "      <td>0.449138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 125.65556447994095, 1.562...</td>\n",
       "      <td>0.453304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 176.59026860117592, 3.447...</td>\n",
       "      <td>0.489491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 4.207449835190346, 1.1490...</td>\n",
       "      <td>0.500646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 1.915615249035909, 8.9229...</td>\n",
       "      <td>0.514169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 0.9504553257659154, 1.9334...</td>\n",
       "      <td>0.522477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>[3.1292152940295637, 4.164806443470297, 2.6175...</td>\n",
       "      <td>0.522576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 5.064906915416941, 1.2457...</td>\n",
       "      <td>0.533282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 11180.112854679755, 2.9362...</td>\n",
       "      <td>0.593843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 1054.034808518496, 7.1849...</td>\n",
       "      <td>0.655846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 0.9313065278729482, 0.883...</td>\n",
       "      <td>0.660392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 24.528388569709932, 4.8812...</td>\n",
       "      <td>0.665252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 3.1844122489492293, 1.919...</td>\n",
       "      <td>0.668115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 5.828086681631248, 1.2263...</td>\n",
       "      <td>0.687393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 0.7242142060517835, 1.166...</td>\n",
       "      <td>0.688749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 1861.1895254259616, 2359....</td>\n",
       "      <td>0.689339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>[0.8523850793171732, 51.52133077799408, 1.9786...</td>\n",
       "      <td>0.690407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 848.7718933545475, 3.2197...</td>\n",
       "      <td>0.695992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "6       Adam         0.0004                6                100   \n",
       "7       Adam         0.0004                6                200   \n",
       "3       Adam         0.0004                4                100   \n",
       "15      Adam         0.0038                6                100   \n",
       "12      Adam         0.0038                4                100   \n",
       "30   RMSprop         0.0004                4                100   \n",
       "9       Adam         0.0038                2                100   \n",
       "4       Adam         0.0004                4                200   \n",
       "5       Adam         0.0004                4                300   \n",
       "33   RMSprop         0.0004                6                100   \n",
       "13      Adam         0.0038                4                200   \n",
       "36   RMSprop         0.0038                2                100   \n",
       "69       SGD         0.0038                6                100   \n",
       "31   RMSprop         0.0004                4                200   \n",
       "27   RMSprop         0.0004                2                100   \n",
       "28   RMSprop         0.0004                2                200   \n",
       "1       Adam         0.0004                2                200   \n",
       "42   RMSprop         0.0038                6                100   \n",
       "8       Adam         0.0004                6                300   \n",
       "10      Adam         0.0038                2                200   \n",
       "\n",
       "                                           loss model     error  \n",
       "6   [1.1165923082444351, 0.8455816553614568, 1.007...  0.426278  \n",
       "7   [2.5006211749550857, 3.2143473901419384, 2.130...  0.448586  \n",
       "3   [0.9783645654251814, 0.792291968610229, 0.8935...  0.449138  \n",
       "15  [1.1165923082444351, 125.65556447994095, 1.562...  0.453304  \n",
       "12  [0.9783645654251814, 176.59026860117592, 3.447...  0.489491  \n",
       "30  [0.9783645654251814, 4.207449835190346, 1.1490...  0.500646  \n",
       "9   [10.181119184275303, 1.915615249035909, 8.9229...  0.514169  \n",
       "4   [7.576681949673912, 0.9504553257659154, 1.9334...  0.522477  \n",
       "5   [3.1292152940295637, 4.164806443470297, 2.6175...  0.522576  \n",
       "33  [1.1165923082444351, 5.064906915416941, 1.2457...  0.533282  \n",
       "13  [7.576681949673912, 11180.112854679755, 2.9362...  0.593843  \n",
       "36  [10.181119184275303, 1054.034808518496, 7.1849...  0.655846  \n",
       "69  [1.1165923082444351, 0.9313065278729482, 0.883...  0.660392  \n",
       "31  [7.576681949673912, 24.528388569709932, 4.8812...  0.665252  \n",
       "27  [10.181119184275303, 3.1844122489492293, 1.919...  0.668115  \n",
       "28  [1.6177626703765782, 5.828086681631248, 1.2263...  0.687393  \n",
       "1   [1.6177626703765782, 0.7242142060517835, 1.166...  0.688749  \n",
       "42  [1.1165923082444351, 1861.1895254259616, 2359....  0.689339  \n",
       "8   [0.8523850793171732, 51.52133077799408, 1.9786...  0.690407  \n",
       "10  [1.6177626703765782, 848.7718933545475, 3.2197...  0.695992  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = best_n_model(track_dict=track_dict, best=20)\n",
    "pd.DataFrame.from_dict(best_models,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = pd.DataFrame.from_dict(best_models,orient='index')\n",
    "df_track = pd.DataFrame.from_dict(track_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../hyperparams_analysis/hyper_Schrod/'\n",
    "df_best.to_csv(file + 'best_dict')\n",
    "df_track.to_csv(file + 'track_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 0.8455816553614568, 1.007...</td>\n",
       "      <td>0.426278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>[2.5006211749550857, 3.2143473901419384, 2.130...</td>\n",
       "      <td>0.448586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 0.792291968610229, 0.8935...</td>\n",
       "      <td>0.449138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 125.65556447994095, 1.562...</td>\n",
       "      <td>0.453304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 176.59026860117592, 3.447...</td>\n",
       "      <td>0.489491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 4.207449835190346, 1.1490...</td>\n",
       "      <td>0.500646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 1.915615249035909, 8.9229...</td>\n",
       "      <td>0.514169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 0.9504553257659154, 1.9334...</td>\n",
       "      <td>0.522477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>[3.1292152940295637, 4.164806443470297, 2.6175...</td>\n",
       "      <td>0.522576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 5.064906915416941, 1.2457...</td>\n",
       "      <td>0.533282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 11180.112854679755, 2.9362...</td>\n",
       "      <td>0.593843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 1054.034808518496, 7.1849...</td>\n",
       "      <td>0.655846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>69</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 0.9313065278729482, 0.883...</td>\n",
       "      <td>0.660392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 24.528388569709932, 4.8812...</td>\n",
       "      <td>0.665252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 3.1844122489492293, 1.919...</td>\n",
       "      <td>0.668115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 5.828086681631248, 1.2263...</td>\n",
       "      <td>0.687393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 0.7242142060517835, 1.166...</td>\n",
       "      <td>0.688749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 1861.1895254259616, 2359....</td>\n",
       "      <td>0.689339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>[0.8523850793171732, 51.52133077799408, 1.9786...</td>\n",
       "      <td>0.690407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 848.7718933545475, 3.2197...</td>\n",
       "      <td>0.695992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "0            6      Adam         0.0004                6                100   \n",
       "1            7      Adam         0.0004                6                200   \n",
       "2            3      Adam         0.0004                4                100   \n",
       "3           15      Adam         0.0038                6                100   \n",
       "4           12      Adam         0.0038                4                100   \n",
       "5           30   RMSprop         0.0004                4                100   \n",
       "6            9      Adam         0.0038                2                100   \n",
       "7            4      Adam         0.0004                4                200   \n",
       "8            5      Adam         0.0004                4                300   \n",
       "9           33   RMSprop         0.0004                6                100   \n",
       "10          13      Adam         0.0038                4                200   \n",
       "11          36   RMSprop         0.0038                2                100   \n",
       "12          69       SGD         0.0038                6                100   \n",
       "13          31   RMSprop         0.0004                4                200   \n",
       "14          27   RMSprop         0.0004                2                100   \n",
       "15          28   RMSprop         0.0004                2                200   \n",
       "16           1      Adam         0.0004                2                200   \n",
       "17          42   RMSprop         0.0038                6                100   \n",
       "18           8      Adam         0.0004                6                300   \n",
       "19          10      Adam         0.0038                2                200   \n",
       "\n",
       "                                           loss model     error  \n",
       "0   [1.1165923082444351, 0.8455816553614568, 1.007...  0.426278  \n",
       "1   [2.5006211749550857, 3.2143473901419384, 2.130...  0.448586  \n",
       "2   [0.9783645654251814, 0.792291968610229, 0.8935...  0.449138  \n",
       "3   [1.1165923082444351, 125.65556447994095, 1.562...  0.453304  \n",
       "4   [0.9783645654251814, 176.59026860117592, 3.447...  0.489491  \n",
       "5   [0.9783645654251814, 4.207449835190346, 1.1490...  0.500646  \n",
       "6   [10.181119184275303, 1.915615249035909, 8.9229...  0.514169  \n",
       "7   [7.576681949673912, 0.9504553257659154, 1.9334...  0.522477  \n",
       "8   [3.1292152940295637, 4.164806443470297, 2.6175...  0.522576  \n",
       "9   [1.1165923082444351, 5.064906915416941, 1.2457...  0.533282  \n",
       "10  [7.576681949673912, 11180.112854679755, 2.9362...  0.593843  \n",
       "11  [10.181119184275303, 1054.034808518496, 7.1849...  0.655846  \n",
       "12  [1.1165923082444351, 0.9313065278729482, 0.883...  0.660392  \n",
       "13  [7.576681949673912, 24.528388569709932, 4.8812...  0.665252  \n",
       "14  [10.181119184275303, 3.1844122489492293, 1.919...  0.668115  \n",
       "15  [1.6177626703765782, 5.828086681631248, 1.2263...  0.687393  \n",
       "16  [1.6177626703765782, 0.7242142060517835, 1.166...  0.688749  \n",
       "17  [1.1165923082444351, 1861.1895254259616, 2359....  0.689339  \n",
       "18  [0.8523850793171732, 51.52133077799408, 1.9786...  0.690407  \n",
       "19  [1.6177626703765782, 848.7718933545475, 3.2197...  0.695992  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file+ 'best_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>number of layer</th>\n",
       "      <th>number of neurons</th>\n",
       "      <th>loss model</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>[10.181119184275303, 7.168606627063127, 5.0295...</td>\n",
       "      <td>0.708292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>[1.6177626703765782, 0.7242142060517835, 1.166...</td>\n",
       "      <td>0.688749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>[4.990864720346963, 0.8818782704871069, 1.5152...</td>\n",
       "      <td>0.725500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>[0.9783645654251814, 0.792291968610229, 0.8935...</td>\n",
       "      <td>0.449138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 0.9504553257659154, 1.9334...</td>\n",
       "      <td>0.522477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>[7.576681949673912, 75507.06133786985, 1.23138...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>[3.1292152940295637, 615803.7256815056, inf, i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>[1.1165923082444351, 1604.0676949091503, 1.474...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>[2.5006211749550857, 22.004259579523932, 16162...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>[0.8523850793171732, 156944.5145627187, inf, i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 optimizer  learning_rate  number of layer  number of neurons  \\\n",
       "0            0      Adam         0.0004                2                100   \n",
       "1            1      Adam         0.0004                2                200   \n",
       "2            2      Adam         0.0004                2                300   \n",
       "3            3      Adam         0.0004                4                100   \n",
       "4            4      Adam         0.0004                4                200   \n",
       "..         ...       ...            ...              ...                ...   \n",
       "76          76       SGD         0.0769                4                200   \n",
       "77          77       SGD         0.0769                4                300   \n",
       "78          78       SGD         0.0769                6                100   \n",
       "79          79       SGD         0.0769                6                200   \n",
       "80          80       SGD         0.0769                6                300   \n",
       "\n",
       "                                           loss model     error  \n",
       "0   [10.181119184275303, 7.168606627063127, 5.0295...  0.708292  \n",
       "1   [1.6177626703765782, 0.7242142060517835, 1.166...  0.688749  \n",
       "2   [4.990864720346963, 0.8818782704871069, 1.5152...  0.725500  \n",
       "3   [0.9783645654251814, 0.792291968610229, 0.8935...  0.449138  \n",
       "4   [7.576681949673912, 0.9504553257659154, 1.9334...  0.522477  \n",
       "..                                                ...       ...  \n",
       "76  [7.576681949673912, 75507.06133786985, 1.23138...       NaN  \n",
       "77  [3.1292152940295637, 615803.7256815056, inf, i...       NaN  \n",
       "78  [1.1165923082444351, 1604.0676949091503, 1.474...       NaN  \n",
       "79  [2.5006211749550857, 22.004259579523932, 16162...       NaN  \n",
       "80  [0.8523850793171732, 156944.5145627187, inf, i...       NaN  \n",
       "\n",
       "[81 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file+ 'track_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
